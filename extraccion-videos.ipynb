{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa las bibliotecas necesarias y define la URL del video de YouTube que deseas descargar\n",
    "import cv2\n",
    "from pytube import YouTube\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=Vbl-pQL4v9M&list=PLv2tHoY9QR8peUi2cNXnXfSCI_w9jB8f4&index=2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\carlo\\\\OneDrive\\\\Documentos\\\\Extraccion de videos\\\\Presidente AMLO presenta ex funcionarios que frenaron desarrollo de CFE.mp4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descarga el video de YouTube utilizando Pytube\n",
    "youtube = YouTube(url)\n",
    "video = youtube.streams.get_highest_resolution()\n",
    "video.download()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda es para poder seleccionar la region que nos interesa capturar y obtener las coordenadas de dicha region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Seleccionar el video y capturar el primer cuadro\n",
    "cap = cv2.VideoCapture('input.mp4')\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Mostrar el video y seleccionar la región deseada\n",
    "region = cv2.selectROI(frame, fromCenter=False)\n",
    "\n",
    "# Establecer el índice del cuadro inicial (en este caso, desde el segundo 30 del video)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, cap.get(cv2.CAP_PROP_FPS) * 60)\n",
    "\n",
    "x = 0\n",
    "y = 0\n",
    "w = 0\n",
    "h = 0\n",
    "\n",
    "# Utiliza el método \"read\" para obtener cada cuadro del video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Si no se pueden obtener más cuadros, sal del bucle\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Recortar la región deseada\n",
    "    x, y, w, h = region\n",
    "    frame = frame[y:y+h, x:x+w]\n",
    "\n",
    "    # Escalar el cuadro si lo deseas\n",
    "    #frame = cv2.resize(frame, (1280, 720))\n",
    "\n",
    "    # Mostrar el cuadro y esperar para continuar\n",
    "    cv2.imshow('Cuadro', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar los recursos utilizados por OpenCV\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Guardar la región recortada en un archivo de imagen\n",
    "cv2.imwrite('region_recortada.jpg', frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979, 470, 257, 152)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Building video output_video.mp4.\n",
      "MoviePy - Writing audio in output_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.editor import *\n",
    "\n",
    "video = cv2.VideoCapture('input.mp4')\n",
    "\n",
    "# Definimos desde que segundo queremos que empiece y termine a capturar el video\n",
    "inicio = 192\n",
    "fin = 222\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "inicio_cuadro = int(inicio * video.get(cv2.CAP_PROP_FPS))\n",
    "fin_cuadro = int(fin * video.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, inicio_cuadro)\n",
    "\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Coordenadas obtenidas gracias a la celda de arriba\n",
    "x1, y1 = 977, 478 # coordenadas de la arista superior izquierda del cuadro de la region seleccionada\n",
    "x2, y2 = 1208, 614 # coordenadas de la arista inferior derecha del cuadro de la region seleccionada\n",
    "\n",
    "new_width, new_height = 854, 480 # dimensiones a las que se va escalar el video generado 854, 480\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video = cv2.VideoWriter('output.mp4', fourcc, fps, (new_width, new_height))\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cropped_frame = frame[y1:y2, x1:x2]\n",
    "\n",
    "    # Convertir a escala de grises\n",
    "    gray_frame = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    scaled_frame = cv2.resize(gray_frame, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    # Convertir la imagen a color de nuevo \n",
    "    scaled_frame = cv2.cvtColor(scaled_frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "    output_video.write(scaled_frame)\n",
    "\n",
    "    if video.get(cv2.CAP_PROP_POS_FRAMES) == fin_cuadro:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "output_video.release()\n",
    "\n",
    "\n",
    "# Con opencv no podemos extraer el video con audio, por lo que hay que obtenerlo por separado y unirlo con el video que extraimos.\n",
    "\n",
    "# Cargar el archivo de video original\n",
    "video_clip = VideoFileClip('input.mp4')\n",
    "\n",
    "# Recortar el video\n",
    "recortado_clip = video_clip.subclip(inicio, fin)\n",
    "\n",
    "# Extraer el audio del video recortado\n",
    "audio = recortado_clip.audio\n",
    "audio.write_audiofile('audio.mp3')\n",
    "\n",
    "# Cargar el archivo de audio y de video\n",
    "audio = AudioFileClip('audio.mp3')\n",
    "video = VideoFileClip('output.mp4')\n",
    "\n",
    "# Agregar el audio al video\n",
    "final_clip = video.set_audio(audio)\n",
    "\n",
    "# Escribir el video final con audio\n",
    "final_clip.write_videofile('output_video.mp4', codec='libx264', fps=video.fps)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
